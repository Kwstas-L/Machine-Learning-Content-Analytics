{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwstas-L/Machine-Learning-Content-Analytics/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br6cwrvjiE3o"
      },
      "source": [
        "# Connect to drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZMlcbsOUkjz"
      },
      "source": [
        "This "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eg_1uTnQasb",
        "outputId": "0d3639da-c0d4-4bab-ac97-94900cb5df01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly2oq2J1SaA8",
        "outputId": "901825cb-faf1-4568-b07e-9c850b4d0371"
      },
      "source": [
        "ls '/content/drive/MyDrive/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdQ2NsLEQwXh",
        "outputId": "69292d1d-6528-489d-e49f-980f14131756"
      },
      "source": [
        "ls '/content/drive/MyDrive/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/  \u001b[01;34m'Machine learning & Content Analytics'\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPVLUNA9USfx",
        "outputId": "7f3c7aaf-982e-4308-d6d0-355f7db80ff8"
      },
      "source": [
        "%cd drive/MyDrive/Machine learning & Content Analytics"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Machine learning & Content Analytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsIdNGMHUfjE",
        "outputId": "38196706-9d70-4cdf-fa8a-640e51e25f6e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code.ipynb                     dataset_aueb_citations_v2.json  dataset.json\n",
            "dataset_aueb_argument_v3.json  dataset_aueb_structure_v2.json  eu_calls.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xUN_QN-Qu5j",
        "outputId": "6fad13d2-1d79-4e65-c083-bc238e79a599"
      },
      "source": [
        "ls '/content/drive/MyDrive/Machine learning & Content Analytics'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code.ipynb                     dataset_aueb_citations_v2.json  dataset.json\n",
            "dataset_aueb_argument_v3.json  dataset_aueb_structure_v2.json  eu_calls.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5vEjDIuQbcd"
      },
      "source": [
        "# Upload the Dataset\n",
        "\n",
        "* In the colab, open the `Files` tab on the left pane.\n",
        "* Drag and drop the `dataset.json` & `dataset_aueb_argument_v3.json` in the root directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM5KZGp2-q3Q"
      },
      "source": [
        "# Load Datasets for argument labels\n",
        "\n",
        "The resulting dataset has one abstract per row. The sentences and the labels are list items. The first sentence of the abstract is its title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "pb2-cA8av2wM",
        "outputId": "154b2ed6-3fb4-478c-83ca-5e1a8da445c3"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Formating of labels: None -> 0, Evidence -> 1, Claim -> 2\n",
        "\n",
        "label1id = {\n",
        "    'NONE': 0,\n",
        "    'EVIDENCE': 1,\n",
        "    'CLAIM': 2}\n",
        "\n",
        "def load_corpus(path, label_mapping=None):\n",
        "    with open(path) as fp:\n",
        "        corpus = json.load(fp)\n",
        "\n",
        "    documents, texts, labels = [], [], []\n",
        "    for abstract in corpus:\n",
        "        documents.append(abstract)\n",
        "        texts.append(corpus[abstract]['sentences'])\n",
        "        if isinstance(label_mapping, dict):\n",
        "            labels.append(\n",
        "                [label_mapping[str(l).upper()]\n",
        "                    for l in corpus[abstract]['labels']])\n",
        "        else:\n",
        "            labels.append([str(l).upper() for l in corpus[abstract]['labels']])\n",
        "\n",
        "    assert len(texts) == len(labels)\n",
        "    data = pd.DataFrame(\n",
        "        zip(documents, texts, labels),\n",
        "        columns=['document', 'sentences', 'labels'])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Loading first Dataset for arguments\n",
        "\n",
        "data = load_corpus('dataset.json', label_mapping=label1id)\n",
        "print(f'Dataset length: {len(data)} abstracts')\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 1669 abstracts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1540</th>\n",
              "      <td>15288288</td>\n",
              "      <td>[Quality of life after palliative treatment fo...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>HOQ_G6B2_PMID_31167228.txt</td>\n",
              "      <td>[Malaria morbidity and mortality following int...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>18064563</td>\n",
              "      <td>[Treatment of depressive symptoms in patients ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1276</th>\n",
              "      <td>16572647</td>\n",
              "      <td>[Effectiveness of neuronavigation in resecting...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1077</th>\n",
              "      <td>16670385</td>\n",
              "      <td>[Randomized multicenter trial of sentinel node...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        document  ...                                      labels\n",
              "1540                    15288288  ...  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1]\n",
              "516   HOQ_G6B2_PMID_31167228.txt  ...  [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0]\n",
              "1050                    18064563  ...           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2]\n",
              "1276                    16572647  ...           [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]\n",
              "1077                    16670385  ...     [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "aoXwwI-TdV_t",
        "outputId": "f3a77a9b-485c-40d3-d335-e0cdfb19a218"
      },
      "source": [
        "# Formating of labels: Neither -> 0, Evidence -> 1, Claim -> 2\n",
        "\n",
        "label2id = {\n",
        "    'NEITHER': 0,\n",
        "    'EVIDENCE': 1,\n",
        "    'CLAIM': 2}\n",
        "\n",
        "# Loading second Dataset for arguments\n",
        "\n",
        "data2 = load_corpus('dataset_aueb_argument_v3.json', label_mapping=label2id)\n",
        "print(f'Dataset length: {len(data2)} abstracts')\n",
        "data2.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 1017 abstracts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>doi: 10.1098/rspb.2018.0841</td>\n",
              "      <td>[Evidence for sexual conflict over major histo...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 1, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>doi: 10.1089/ars.2017.7373</td>\n",
              "      <td>[SIRT1 Controls Acetaminophen Hepatotoxicity b...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>doi: 10.1038/s41467-018-06962-z</td>\n",
              "      <td>[Determinants of promoter and enhancer transcr...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 1, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>doi: 10.5194/acp-2019-533</td>\n",
              "      <td>[Surprising similarities in model and observat...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 1, 2, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>doi: 10.1021/acs.chemrev.8b00580</td>\n",
              "      <td>[Principles and Applications of Nucleic Acid S...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             document  ...                                   labels\n",
              "644       doi: 10.1098/rspb.2018.0841  ...                 [0, 0, 0, 1, 1, 1, 1, 2]\n",
              "579        doi: 10.1089/ars.2017.7373  ...  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0]\n",
              "425   doi: 10.1038/s41467-018-06962-z  ...                 [0, 0, 0, 1, 1, 1, 1, 2]\n",
              "975         doi: 10.5194/acp-2019-533  ...              [0, 0, 0, 0, 0, 1, 1, 2, 2]\n",
              "291  doi: 10.1021/acs.chemrev.8b00580  ...                 [0, 0, 0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "J663ccXddboQ",
        "outputId": "74627023-b684-4c43-9076-ff2f47019406"
      },
      "source": [
        "data2[data2[\"document\"].duplicated()==True] # check for duplicates\n",
        "data[data[\"document\"].duplicated()==True] # check for duplicates"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [document, sentences, labels]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "YfCEx8Y6db52",
        "outputId": "11caa511-d012-4fec-b93e-caf58f6878c1"
      },
      "source": [
        "# Combining the two datasets to one\n",
        "\n",
        "data_total_argument=pd.concat([data, data2], ignore_index=True)\n",
        "print(f'Dataset length: {len(data_total_argument)} abstracts')\n",
        "data_total_argument.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 2686 abstracts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1600</th>\n",
              "      <td>10901475</td>\n",
              "      <td>[The additive intraocular pressure-lowering ef...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>EIK_G4B3_CorpusID_17835679.txt</td>\n",
              "      <td>[﻿Violence against women increases the risk of...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>ABC_G1B2_10.1016_j.jrurstud.2019.10.014.txt</td>\n",
              "      <td>[Rural innovation system: Revitalize the count...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>LMN_G5B4_CorpusID_17605839.txt</td>\n",
              "      <td>[Title: Ecological Restoration and Global Clim...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>LMN_G5B4_10.1038_s41558-020-0874-1.txt</td>\n",
              "      <td>[Title: Increasing threat of coastal groundwat...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         document  ...                                             labels\n",
              "1600                                     10901475  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, ...\n",
              "189                EIK_G4B3_CorpusID_17835679.txt  ...      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0]\n",
              "631   ABC_G1B2_10.1016_j.jrurstud.2019.10.014.txt  ...                        [0, 0, 0, 0, 0, 1, 0, 0, 2]\n",
              "730                LMN_G5B4_CorpusID_17605839.txt  ...                                 [0, 0, 0, 0, 1, 2]\n",
              "722        LMN_G5B4_10.1038_s41558-020-0874-1.txt  ...                              [0, 0, 0, 0, 1, 0, 2]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yibkZ7X6dsUh",
        "outputId": "68a94641-82f0-40a3-c033-abe4f1643eed"
      },
      "source": [
        "data_total_argument.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2686 entries, 0 to 2685\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   document   2686 non-null   object\n",
            " 1   sentences  2686 non-null   object\n",
            " 2   labels     2686 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 63.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "-cKLueWv4ptE",
        "outputId": "86bb3129-d101-4483-a1c1-704ae0888c5f"
      },
      "source": [
        "data_total_argument.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2686</td>\n",
              "      <td>2686</td>\n",
              "      <td>2686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2686</td>\n",
              "      <td>2678</td>\n",
              "      <td>1298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>28291960</td>\n",
              "      <td>[Synthesis of Dibenzo[hi,st\\n]ovalene and Its ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        document  ...                 labels\n",
              "count       2686  ...                   2686\n",
              "unique      2686  ...                   1298\n",
              "top     28291960  ...  [0, 0, 0, 0, 0, 1, 2]\n",
              "freq           1  ...                     40\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiGTLjtY-8OM"
      },
      "source": [
        "## Split Documents\n",
        "For the cases we want the sentences separated, the following splits the documents. I keep the same document index in a new column in order to re-group the sentences to a document (e.g., after predictions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "v7a3iUE3m-3Y",
        "outputId": "e3876700-887b-4586-d402-a35f86c60145"
      },
      "source": [
        "#@title Split to sentences\n",
        "sentences = data_total_argument['sentences'].explode().reset_index().rename(\n",
        "    columns={'index': 'doc_id', 'sentences': 'sentence'})\n",
        "sentences\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gender Differences in Anxiety and Depression b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Abstract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Background/aims: The aim of this prospective s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Methods: AUD severity, state and trait anxiety...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Follow-up assessments were performed at 6 and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31999</th>\n",
              "      <td>2685</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32000</th>\n",
              "      <td>2685</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32001</th>\n",
              "      <td>2685</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32002</th>\n",
              "      <td>2685</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32003</th>\n",
              "      <td>2685</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32004 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence\n",
              "0           0  Gender Differences in Anxiety and Depression b...\n",
              "1           0                                           Abstract\n",
              "2           0  Background/aims: The aim of this prospective s...\n",
              "3           0  Methods: AUD severity, state and trait anxiety...\n",
              "4           0  Follow-up assessments were performed at 6 and ...\n",
              "...       ...                                                ...\n",
              "31999    2685  Instead, SBPs sample a range of conformations ...\n",
              "32000    2685  Certain non-transported ligands leave the stru...\n",
              "32001    2685  Intriguingly, in some cases, similar SBP confo...\n",
              "32002    2685  In this case, the inability for transport aris...\n",
              "32003    2685  Our results reveal the complex interplay betwe...\n",
              "\n",
              "[32004 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Eh7LJ3evZC3o",
        "outputId": "a21a2405-2282-4b18-eb30-5f29ebec7f5c"
      },
      "source": [
        "#@title and the corresponding labels\n",
        "labels = data_total_argument['labels'].explode().reset_index().rename(\n",
        "    columns={'index': 'doc_id', 'labels': 'label'})\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31999</th>\n",
              "      <td>2685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32000</th>\n",
              "      <td>2685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32001</th>\n",
              "      <td>2685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32002</th>\n",
              "      <td>2685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32003</th>\n",
              "      <td>2685</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32004 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id label\n",
              "0           0     0\n",
              "1           0     0\n",
              "2           0     0\n",
              "3           0     0\n",
              "4           0     0\n",
              "...       ...   ...\n",
              "31999    2685     0\n",
              "32000    2685     0\n",
              "32001    2685     0\n",
              "32002    2685     0\n",
              "32003    2685     2\n",
              "\n",
              "[32004 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "jDPIxQalinnf",
        "outputId": "3cee904c-5f2a-4c58-b076-1bcb07d0027c"
      },
      "source": [
        "#@title Regroup document using the index\n",
        "arguments = pd.merge(sentences,labels, left_index=True, right_index=True).rename( \n",
        "    columns = {\"doc_id_x\" : \"doc_id\"}).drop( columns= \"doc_id_y\")\n",
        "arguments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gender Differences in Anxiety and Depression b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Abstract</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Background/aims: The aim of this prospective s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Methods: AUD severity, state and trait anxiety...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Follow-up assessments were performed at 6 and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31999</th>\n",
              "      <td>2685</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32000</th>\n",
              "      <td>2685</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32001</th>\n",
              "      <td>2685</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32002</th>\n",
              "      <td>2685</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32003</th>\n",
              "      <td>2685</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32004 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence label\n",
              "0           0  Gender Differences in Anxiety and Depression b...     0\n",
              "1           0                                           Abstract     0\n",
              "2           0  Background/aims: The aim of this prospective s...     0\n",
              "3           0  Methods: AUD severity, state and trait anxiety...     0\n",
              "4           0  Follow-up assessments were performed at 6 and ...     0\n",
              "...       ...                                                ...   ...\n",
              "31999    2685  Instead, SBPs sample a range of conformations ...     0\n",
              "32000    2685  Certain non-transported ligands leave the stru...     0\n",
              "32001    2685  Intriguingly, in some cases, similar SBP confo...     0\n",
              "32002    2685  In this case, the inability for transport aris...     0\n",
              "32003    2685  Our results reveal the complex interplay betwe...     2\n",
              "\n",
              "[32004 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCWUkK5blJRL"
      },
      "source": [
        "### Extract - Transform data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2B8odEMlKay",
        "outputId": "c57cb8b9-ec02-49b7-a3cb-c148d53172a5"
      },
      "source": [
        "# The raw input (sentences)\n",
        "X_arguments = arguments['sentence']\n",
        "\n",
        "X_arguments.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Gender Differences in Anxiety and Depression b...\n",
              "1                                              Abstract\n",
              "2     Background/aims: The aim of this prospective s...\n",
              "3     Methods: AUD severity, state and trait anxiety...\n",
              "4     Follow-up assessments were performed at 6 and ...\n",
              "5     A between- and within-subjects analyses explor...\n",
              "6     The predictive value of anxiety and depression...\n",
              "7     Results: Females had higher levels of anxiety ...\n",
              "8     Trait anxiety and depression significantly inc...\n",
              "9     Both state and trait anxiety levels at the 6-m...\n",
              "10    Conversely, in females, depression level at th...\n",
              "11    Conclusions: In both genders, the psychopathol...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6AwL9N-lUK2",
        "outputId": "9fe6911e-7b39-4d46-d04f-76ad6886bd49"
      },
      "source": [
        "# The raw output (Labels : Neither / None -> 0, Evidence -> 1, Claim -> 2)\n",
        "y_arguments = arguments['label']\n",
        "\n",
        "y_arguments.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     1\n",
              "9     1\n",
              "10    1\n",
              "11    2\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nDgz88Am8aL"
      },
      "source": [
        "### Splitting Dataset Procedure\n",
        "\n",
        "---\n",
        "* Training dataset\n",
        "* Validation dataset\n",
        "* Test dataset (unseen dataset)\n",
        "---\n",
        "At first, we will split the Original dataset into two parts:\n",
        "\n",
        "* Train-Validation dataset\n",
        "* Test dataset \n",
        "\n",
        "Secondly, we will split the Train-Validation dataset into another two parts:\n",
        "* Train dataset\n",
        "* Validation dataset\n",
        "\n",
        "#### Note: Stratified sampling was used\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKBweeEZpsop",
        "outputId": "a3caec49-a0fa-4ec3-a2f3-ed6c921cca43"
      },
      "source": [
        "len(arguments) / len(arguments[arguments['label'] != 0]) #@markdown 32004 (number of sentences)  / 9629 (event of interest) = 3.23 %\n",
        "######### to be checked\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.32370962716793"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJed-i8Rm3uk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_val_arg, X_test_arg, y_train_val_arg, y_test_arg = train_test_split(X_arguments,\n",
        "                                                            y_arguments,\n",
        "                                                            test_size=0.10,\n",
        "                                                            random_state=10,\n",
        "                                                            stratify=y_arguments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goc5jQomo4Uo"
      },
      "source": [
        "X_train_arg, X_val_arg, y_train_arg, y_val_arg = train_test_split(X_train_val_arg,\n",
        "                                                  y_train_val_arg,\n",
        "                                                  test_size=0.11, \n",
        "                                                  random_state=50,\n",
        "                                                  stratify=y_train_val_arg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VaFHpn5oSpo",
        "outputId": "2f0752f8-92a6-4ce1-f070-309381aa4b41"
      },
      "source": [
        "print(f'X_train_val_arg shape: {X_train_val_arg.shape}')\n",
        "print(f'y_train_val_arg shape: {y_train_val_arg.shape}')\n",
        "print()\n",
        "\n",
        "print(f'X_train_arg shape: {X_train_arg.shape}')\n",
        "print(f'y_train_arg shape: {y_train_arg.shape}')\n",
        "print()\n",
        "\n",
        "print(f'X_val_arg shape: {X_val_arg.shape}')\n",
        "print(f'y_val_arg shape: {y_val_arg.shape}')\n",
        "\n",
        "print()\n",
        "print(f'X_test_arg shape: {X_test_arg.shape}')\n",
        "print(f'y_test_arg shape: {y_test_arg.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_val_arg shape: (28803,)\n",
            "y_train_val_arg shape: (28803,)\n",
            "\n",
            "X_train_arg shape: (25634,)\n",
            "y_train_arg shape: (25634,)\n",
            "\n",
            "X_val_arg shape: (3169,)\n",
            "y_val_arg shape: (3169,)\n",
            "\n",
            "X_test_arg shape: (3201,)\n",
            "y_test_arg shape: (3201,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F_Q17sZzejuf",
        "outputId": "16d7bad8-cd54-4400-fede-39932f666355"
      },
      "source": [
        "import nltk\n",
        "from pprint import pprint\n",
        "\n",
        "nltk.download('all')\n",
        "\n",
        "nltk.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.5'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAFTVFjxXgIU"
      },
      "source": [
        "# Baseline Model for Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo7iNVxIZzOj"
      },
      "source": [
        "### Create a vocabulary with all tokens from the argument training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PPAUL9t2wvf",
        "outputId": "d6471d21-f08e-4b47-9edc-6d8a17e21567"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def create_vocabulary(data):\n",
        "\n",
        "  tokenizer = RegexpTokenizer(r'[a-zA-Z]+') # keep only characters a-z or A-Z\n",
        "  en_stop = stopwords.words('english') # english stopwords\n",
        "\n",
        "  vocabulary=[]\n",
        "  \n",
        "  for text in data:\n",
        "    text = text.lower().strip()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    filtered = [w for w in tokens if w not in en_stop]\n",
        "    vocabulary.extend(filtered)\n",
        "\n",
        "  return vocabulary\n",
        "\n",
        "vocabulary_arg = create_vocabulary(X_train_arg) # the training dataset vocabulary for all the arguments\n",
        "\n",
        "count_vocabulary_arg = Counter(vocabulary_arg)\n",
        "top_10_words_in_arg = count_vocabulary_arg.most_common(10)\n",
        "top_10_words_in_arg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('patients', 3515),\n",
              " ('p', 2166),\n",
              " ('study', 1956),\n",
              " ('health', 1771),\n",
              " ('group', 1628),\n",
              " ('treatment', 1511),\n",
              " ('women', 1340),\n",
              " ('cancer', 1297),\n",
              " ('results', 1237),\n",
              " ('climate', 1222)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWNKKLqmroV"
      },
      "source": [
        "### Create a vocabulary with all tokens from the argument training dataset one for the evidence and one for the claim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz3uLn0pdnMZ",
        "outputId": "c9dc26f0-69c9-4150-f03d-99e0d358abde"
      },
      "source": [
        "# create a list with the location of the sentences labeled 1 : evidence or 2 : claim in the training argument dataset\n",
        "\n",
        "def locate_argument(dataset,label_id=0):\n",
        "\n",
        "  labeled_argument = []\n",
        "\n",
        "  for location , label in enumerate(dataset):\n",
        "    if (label == label_id):\n",
        "      labeled_argument.append(location)\n",
        "\n",
        "  return labeled_argument\n",
        "\n",
        "labeled_argument_evidence = locate_argument(y_train_arg,1)\n",
        "\n",
        "labeled_argument_claim = locate_argument(y_train_arg,2)\n",
        "\n",
        "print(\"Number of sentences labeled 1 & 2 in the y_train_arg dataset: \",len(locate_argument(y_train_arg,1)),\"+\",len(locate_argument(y_train_arg,2)))\n",
        "\n",
        "print(\"Number of sentences labeled 1 & 2 in the y_val_arg dataset: \",len(locate_argument(y_val_arg,1)),\"+\",len(locate_argument(y_val_arg,2)))\n",
        "\n",
        "print(\"Number of sentences labeled 1 & 2 in the y_test_arg dataset: \",len(locate_argument(y_test_arg,1)),\"+\",len(locate_argument(y_test_arg,2)))\n",
        "\n",
        "print(\"Total\",len(arguments[arguments[\"label\"]!=0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences labeled 1 & 2 in the y_train_arg dataset:  4974 + 2738\n",
            "Number of sentences labeled 1 & 2 in the y_val_arg dataset:  615 + 339\n",
            "Number of sentences labeled 1 & 2 in the y_test_arg dataset:  621 + 342\n",
            "Total 9629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwyvpyUGobNB",
        "outputId": "2d783742-ca6a-4238-f528-b9c44d8fd42e"
      },
      "source": [
        "vocabulary_arg_evidence = create_vocabulary(X_train_arg.iloc[labeled_argument_evidence]) # the training dataset vocabulary with only the arguments labeled as evidence\n",
        "\n",
        "count_vocabulary_arg_evidence = Counter(vocabulary_arg_evidence)\n",
        "top_10_words_in_arg_evidence = count_vocabulary_arg_evidence.most_common(10)\n",
        "top_10_words_in_arg_evidence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('p', 1754),\n",
              " ('group', 886),\n",
              " ('patients', 836),\n",
              " ('ci', 602),\n",
              " ('months', 495),\n",
              " ('significant', 483),\n",
              " ('significantly', 465),\n",
              " ('results', 391),\n",
              " ('compared', 379),\n",
              " ('higher', 345)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO4KPgFGj_-F",
        "outputId": "1cbfa939-4045-408e-9bb2-6f10a489eb2f"
      },
      "source": [
        "vocabulary_arg_claim = create_vocabulary(X_train_arg.iloc[labeled_argument_claim]) # the training dataset vocabulary with only the arguments labeled as claim\n",
        "\n",
        "count_vocabulary_arg_claim = Counter(vocabulary_arg_claim)\n",
        "top_10_words_in_arg_claim = count_vocabulary_arg_claim.most_common(10)\n",
        "top_10_words_in_arg_claim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('patients', 419),\n",
              " ('treatment', 251),\n",
              " ('results', 227),\n",
              " ('cancer', 206),\n",
              " ('health', 206),\n",
              " ('study', 200),\n",
              " ('may', 192),\n",
              " ('conclusions', 191),\n",
              " ('conclusion', 169),\n",
              " ('climate', 162)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uekuDIs_-tor"
      },
      "source": [
        "# Vocabularies with the 50 most encountered tokens \n",
        "\n",
        "# from the whole train dataset\n",
        "most_common_vocab = sorted(count_vocabulary_arg, key = count_vocabulary_arg.get, reverse=True)[:50] \n",
        "\n",
        "# only claims from the train dataset\n",
        "most_common_vocab_claims = sorted(count_vocabulary_arg_claim, key = count_vocabulary_arg_claim.get, reverse=True)[:50]\n",
        "\n",
        "# only evidence from the train dataset\n",
        "most_common_vocab_evidence = sorted(count_vocabulary_arg_evidence, key = count_vocabulary_arg_evidence.get, reverse=True)[:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKT7eKJ9sMBR",
        "outputId": "6f8e77aa-9adb-4d56-dc93-6123c72604c4"
      },
      "source": [
        "set_words_arg = set(most_common_vocab)\n",
        "set_claim_words = set(most_common_vocab_claims)\n",
        "set_evidence_words = set(most_common_vocab_evidence)\n",
        "\n",
        "diff_total_to_claims = set_claim_words - set_words_arg\n",
        "diff_total_to_evidence = set_evidence_words - set_words_arg\n",
        "\n",
        "print(\"Most common Tokens encountered mostly in the sentences labeled claim:\",len(diff_total_to_claims))\n",
        "print(\"Most common Tokens encountered mostly in the sentences labeled evidence:\",len(diff_total_to_evidence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common Tokens encountered mostly in the sentences labeled claim: 20\n",
            "Most common Tokens encountered mostly in the sentences labeled evidence: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHoISVnrvAZ3",
        "outputId": "f4023eae-6e00-4523-d215-699e09511189"
      },
      "source": [
        "# words mostly used for one of the labels\n",
        "\n",
        "def words_mostly_used(diff,count, print_1 = \"print\"):\n",
        "\n",
        "  words_used = {}\n",
        "  for word in diff:\n",
        "    words_used [word] =  count[word]\n",
        "\n",
        "  sorted_list_of_counted_words = []\n",
        "  sorted_list_of_counted_words = sorted(words_used, key = words_used.get, reverse=True) [:50]\n",
        "\n",
        "  if (print_1 != \"print\"):\n",
        "    for w in sorted_list_of_counted_words:\n",
        "      print(w, count[w])\n",
        "  else:\n",
        "    return sorted_list_of_counted_words\n",
        "\n",
        "words_mostly_used(diff_total_to_claims,count_vocabulary_arg_claim, print)\n",
        "words_baseline_model_claim = words_mostly_used(diff_total_to_claims,count_vocabulary_arg_claim)\n",
        "\n",
        "print()\n",
        "\n",
        "words_mostly_used(diff_total_to_evidence,count_vocabulary_arg_evidence, print)\n",
        "words_baseline_model_evidence= words_mostly_used(diff_total_to_evidence,count_vocabulary_arg_evidence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "may 192\n",
            "conclusions 191\n",
            "conclusion 169\n",
            "effective 130\n",
            "findings 120\n",
            "suggest 105\n",
            "qol 102\n",
            "could 101\n",
            "effect 93\n",
            "improve 91\n",
            "advanced 88\n",
            "overall 87\n",
            "therapy 87\n",
            "future 84\n",
            "however 82\n",
            "better 80\n",
            "increased 80\n",
            "response 78\n",
            "term 77\n",
            "improved 77\n",
            "\n",
            "respectively 331\n",
            "vs 283\n",
            "difference 254\n",
            "increased 242\n",
            "median 232\n",
            "baseline 225\n",
            "differences 220\n",
            "lower 219\n",
            "showed 217\n",
            "observed 210\n",
            "scores 202\n",
            "arm 201\n",
            "found 197\n",
            "reported 196\n",
            "overall 191\n",
            "year 189\n",
            "rate 187\n",
            "versus 186\n",
            "mm 178\n",
            "per 174\n",
            "control 168\n",
            "levels 166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRQdKCj2LRAv",
        "outputId": "a0e5cdd0-099e-4a51-cb4c-95b54eebaa10"
      },
      "source": [
        "# Common tokens in the two lists\n",
        "\n",
        "common_tokens_in_the_2_lists = list(set(words_baseline_model_claim).intersection(words_baseline_model_evidence))\n",
        "common_tokens_in_the_2_lists"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['overall', 'increased']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVvwY3MnacdQ",
        "outputId": "5ef1658d-002f-45bb-f60c-18d2b779fd93"
      },
      "source": [
        "print(\" # of occurences 'increased' in claims:\",count_vocabulary_arg_claim[\"increased\"])\n",
        "print(\" # of occurences 'increased' in evidence:\",count_vocabulary_arg_evidence[\"increased\"])\n",
        "print(\" # of occurences 'overall' in claims:\",count_vocabulary_arg_claim[\"overall\"])\n",
        "print(\" # of occurences 'overall' in evidence:\",count_vocabulary_arg_evidence[\"overall\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " # of occurences 'increased' in claims: 80\n",
            " # of occurences 'increased' in evidence: 242\n",
            " # of occurences 'overall' in claims: 87\n",
            " # of occurences 'overall' in evidence: 191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7QhDPMx1Rbm"
      },
      "source": [
        "### The tokens mostly used in claim or evidence sentences where tested to select the best ones for the baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx57DyyYgeEb"
      },
      "source": [
        "### Predictions\n",
        "All the tokens from the words_baseline_model_claim & words_baseline_model_evidence where used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4WLrcPme1Ks"
      },
      "source": [
        "import re\n",
        "\n",
        "y_predicted_for_validation_all_words = [0] * len(X_val_arg)\n",
        "\n",
        "for code_word_1 in words_baseline_model_claim:\n",
        "\n",
        "  for index_1 , sentence_1 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_1 + r'\\b', sentence_1.lower()):\n",
        "      if code_word_1 not in common_tokens_in_the_2_lists: # 'Increased' & 'Overall' appear mostly as tokens for evidence\n",
        "        y_predicted_for_validation_all_words [index_1] = 2\n",
        "\n",
        "for code_word_2 in words_baseline_model_evidence:\n",
        "\n",
        "  for index_2 , sentence_2 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_2 + r'\\b', sentence_2.lower()):\n",
        "      y_predicted_for_validation_all_words [index_2] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JK6k3d5gnb_"
      },
      "source": [
        "### The top 10 tokens from the words_baseline_model_claim & words_baseline_model_evidence where used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxgaU2XrfWAU"
      },
      "source": [
        "# The top 10 tokens from the words_baseline_model_claim & words_baseline_model_evidence where used\n",
        "\n",
        "y_predicted_for_validation_top_10 = [0] * len(X_val_arg)\n",
        "\n",
        "for code_word_1 in words_baseline_model_claim [:10]:\n",
        "\n",
        "  for index_1 , sentence_1 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_1 + r'\\b', sentence_1.lower()):\n",
        "      if code_word_1 not in common_tokens_in_the_2_lists: # 'Increased' & 'Overall' appear mostly as tokens for evidence\n",
        "        y_predicted_for_validation_top_10 [index_1] = 2\n",
        "\n",
        "for code_word_2 in words_baseline_model_evidence [:10]:\n",
        "\n",
        "  for index_2 , sentence_2 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_2 + r'\\b', sentence_2.lower()):\n",
        "      y_predicted_for_validation_top_10 [index_2] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmahGT-hgsjG"
      },
      "source": [
        "### The top 5 tokens from the words_baseline_model_claim & words_baseline_model_evidence where used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPs6hXjlfu-f"
      },
      "source": [
        "# The top 5 tokens from the words_baseline_model_claim & words_baseline_model_evidence where used\n",
        "\n",
        "y_predicted_for_validation_top_5 = [0] * len(X_val_arg)\n",
        "\n",
        "for code_word_1 in words_baseline_model_claim[:5]:\n",
        "  for index_1 , sentence_1 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_1 + r'\\b', sentence_1.lower()):\n",
        "      if code_word_1 not in common_tokens_in_the_2_lists: # 'Increased' & 'Overall' appear mostly as tokens for evidence\n",
        "        y_predicted_for_validation_top_5 [index_1] = 2\n",
        "\n",
        "for code_word_2 in words_baseline_model_evidence[:5]:\n",
        "  for index_2 , sentence_2 in enumerate(X_val_arg):\n",
        "    if re.search(r'\\b' + code_word_2 + r'\\b', sentence_2.lower()):\n",
        "      y_predicted_for_validation_top_5 [index_2] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cDAArDyiL1M"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUDJdj7tFGRI"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9RlfUbklpZR"
      },
      "source": [
        "conf_mat_all_words = confusion_matrix ( y_true = y_val_arg.to_list(), y_pred = y_predicted_for_validation_all_words)\n",
        "conf_mat_top_10 = confusion_matrix ( y_true = y_val_arg.to_list(), y_pred = y_predicted_for_validation_top_10)\n",
        "conf_mat_top_5 = confusion_matrix ( y_true = y_val_arg.to_list(), y_pred = y_predicted_for_validation_top_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4i69CYn8Mw"
      },
      "source": [
        "### Confusion matrix for all words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "0BL0c63nmp9d",
        "outputId": "652c2f99-e87b-4b68-fb10-d36175622939"
      },
      "source": [
        "pd.DataFrame( conf_mat_all_words, columns = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"], index = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>None: 0</th>\n",
              "      <th>Evidence: 1</th>\n",
              "      <th>Claim: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>None: 0</th>\n",
              "      <td>1500</td>\n",
              "      <td>398</td>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Evidence: 1</th>\n",
              "      <td>242</td>\n",
              "      <td>313</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Claim: 2</th>\n",
              "      <td>137</td>\n",
              "      <td>88</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             None: 0  Evidence: 1  Claim: 2\n",
              "None: 0         1500          398       317\n",
              "Evidence: 1      242          313        60\n",
              "Claim: 2         137           88       114"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIO410QsoBuI"
      },
      "source": [
        "### Confusion matrix for top 10 words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "gu9wM9ZGnT86",
        "outputId": "553f473f-4873-443f-b38e-9934dfa872fb"
      },
      "source": [
        "pd.DataFrame( conf_mat_top_10, columns = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"], index = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>None: 0</th>\n",
              "      <th>Evidence: 1</th>\n",
              "      <th>Claim: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>None: 0</th>\n",
              "      <td>1848</td>\n",
              "      <td>179</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Evidence: 1</th>\n",
              "      <td>375</td>\n",
              "      <td>198</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Claim: 2</th>\n",
              "      <td>193</td>\n",
              "      <td>49</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             None: 0  Evidence: 1  Claim: 2\n",
              "None: 0         1848          179       188\n",
              "Evidence: 1      375          198        42\n",
              "Claim: 2         193           49        97"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE8_r64joEvs"
      },
      "source": [
        "### Confusion matrix for top 5 words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "f85eZq6vnUd6",
        "outputId": "d8fe13ec-101d-4b00-b003-60e2862978a0"
      },
      "source": [
        "pd.DataFrame( conf_mat_top_5, columns = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"], index = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>None: 0</th>\n",
              "      <th>Evidence: 1</th>\n",
              "      <th>Claim: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>None: 0</th>\n",
              "      <td>2047</td>\n",
              "      <td>82</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Evidence: 1</th>\n",
              "      <td>470</td>\n",
              "      <td>124</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Claim: 2</th>\n",
              "      <td>244</td>\n",
              "      <td>19</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             None: 0  Evidence: 1  Claim: 2\n",
              "None: 0         2047           82        86\n",
              "Evidence: 1      470          124        21\n",
              "Claim: 2         244           19        76"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkCaOCwmossJ"
      },
      "source": [
        "### Classification reports for each method used in the validation dataset to predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqsxzVnxob73",
        "outputId": "7ac82498-711b-4b2f-93ae-28c0e699511b"
      },
      "source": [
        "print( classification_report( y_true = y_val_arg.to_list() , y_pred = y_predicted_for_validation_all_words) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.68      0.73      2215\n",
            "           1       0.39      0.51      0.44       615\n",
            "           2       0.23      0.34      0.27       339\n",
            "\n",
            "    accuracy                           0.61      3169\n",
            "   macro avg       0.47      0.51      0.48      3169\n",
            "weighted avg       0.66      0.61      0.63      3169\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_2Xl9_DpCsd",
        "outputId": "8d19e720-1b1e-44b8-f349-330e4afe32db"
      },
      "source": [
        "print( classification_report( y_true = y_val_arg.to_list() , y_pred = y_predicted_for_validation_top_10) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.80      2215\n",
            "           1       0.46      0.32      0.38       615\n",
            "           2       0.30      0.29      0.29       339\n",
            "\n",
            "    accuracy                           0.68      3169\n",
            "   macro avg       0.51      0.48      0.49      3169\n",
            "weighted avg       0.66      0.68      0.66      3169\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxBOwhCCqiZd",
        "outputId": "db929614-1e58-4d31-ac42-fc4685b10948"
      },
      "source": [
        "print( classification_report( y_true = y_val_arg.to_list() , y_pred = y_predicted_for_validation_top_5) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.92      0.82      2215\n",
            "           1       0.55      0.20      0.30       615\n",
            "           2       0.42      0.22      0.29       339\n",
            "\n",
            "    accuracy                           0.71      3169\n",
            "   macro avg       0.57      0.45      0.47      3169\n",
            "weighted avg       0.67      0.71      0.66      3169\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnd_WvqrqjJP"
      },
      "source": [
        "### Selected model: top 5 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpE1gMCUqkI6"
      },
      "source": [
        "# Predictions in the test data set\n",
        "\n",
        "final_baseline_model_claim = words_baseline_model_claim [:5]\n",
        "final_baseline_model_evidence = words_baseline_model_evidence [:5]\n",
        "\n",
        "y_predicted_for_testing_arguments = [0] * len(X_test_arg)\n",
        "\n",
        "for code_word_1 in final_baseline_model_claim :\n",
        "  for index_1 , sentence_1 in enumerate(X_test_arg):\n",
        "    if re.search(r'\\b' + code_word_1 + r'\\b', sentence_1.lower()):\n",
        "      if code_word_1 not in common_tokens_in_the_2_lists: # 'Increased' & 'Overall' appear mostly as tokens for evidence\n",
        "        y_predicted_for_testing_arguments [index_1] = 2\n",
        "\n",
        "for code_word_2 in final_baseline_model_evidence :\n",
        "  for index_2 , sentence_2 in enumerate(X_test_arg):\n",
        "    if re.search(r'\\b' + code_word_2 + r'\\b', sentence_2.lower()):\n",
        "      y_predicted_for_testing_arguments [index_2] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y66CDmhkpY7u"
      },
      "source": [
        "### Confusion Matrix & Classification report for selected baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "nIQ4X2oBpnnG",
        "outputId": "e4b7294a-0b24-46f1-bb07-0659368dd026"
      },
      "source": [
        "baseline_final_conf_mat_test = confusion_matrix ( y_true = y_test_arg.to_list(), y_pred = y_predicted_for_testing_arguments)\n",
        "pd.DataFrame( baseline_final_conf_mat_test, columns = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"], index = [\"None: 0\",\"Evidence: 1\",\"Claim: 2\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>None: 0</th>\n",
              "      <th>Evidence: 1</th>\n",
              "      <th>Claim: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>None: 0</th>\n",
              "      <td>2076</td>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Evidence: 1</th>\n",
              "      <td>483</td>\n",
              "      <td>126</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Claim: 2</th>\n",
              "      <td>236</td>\n",
              "      <td>12</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             None: 0  Evidence: 1  Claim: 2\n",
              "None: 0         2076           83        79\n",
              "Evidence: 1      483          126        12\n",
              "Claim: 2         236           12        94"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12QCK-zEpn-B",
        "outputId": "d3d11ad0-5922-4031-f034-d35215930fce"
      },
      "source": [
        "print( classification_report( y_true = y_test_arg.to_list() , y_pred = y_predicted_for_testing_arguments) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.93      0.82      2238\n",
            "           1       0.57      0.20      0.30       621\n",
            "           2       0.51      0.27      0.36       342\n",
            "\n",
            "    accuracy                           0.72      3201\n",
            "   macro avg       0.61      0.47      0.49      3201\n",
            "weighted avg       0.68      0.72      0.67      3201\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDctk-R26tMo"
      },
      "source": [
        "# Structure dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4TtgY2YBS4e"
      },
      "source": [
        "# Upload the Dataset\n",
        "\n",
        "* In the colab, open the `Files` tab on the left pane.\n",
        "* Drag and drop the `dataset_aueb_structure_v2.json` in the root directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeCFRZuoAezs"
      },
      "source": [
        "The `dataset_aueb_structure_v2.json` file has a problematic entry. The doi: 10.1111/jnc.13838 was deleted manually before being loaded in collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "D69ekWMAFEV9",
        "outputId": "00b8128a-e3e5-4737-e6de-844634bb9e22"
      },
      "source": [
        "data_structure = load_corpus('dataset_aueb_structure_v2.json')\n",
        "print(f'Dataset length: {len(data_structure)} abstracts')\n",
        "data_structure.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length: 1014 abstracts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>doi: 10.1172/jci.insight.96029</td>\n",
              "      <td>[Noninvasive gene delivery to foveal cones for...</td>\n",
              "      <td>[NEITHER, BACKGROUND, BACKGROUND, OBJECTIVE, B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>doi: 10.1126/sciadv.1701676</td>\n",
              "      <td>[Unlocking data sets by calibrating population...</td>\n",
              "      <td>[NEITHER, BACKGROUND, BACKGROUND, BACKGROUND, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>doi: 10.3390/atmos9070240</td>\n",
              "      <td>[From Tropospheric Folding to Khamsin and Foeh...</td>\n",
              "      <td>[NEITHER, BACKGROUND, OBJECTIVE, METHOD, RESUL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>doi: 10.1371/journal.pone.0154077</td>\n",
              "      <td>[A Regional Reduction in Ito and IKACh in the ...</td>\n",
              "      <td>[NEITHER, BACKGROUND, METHOD, METHOD, RESULT, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>doi: 10.1016/j.abb.2018.03.026</td>\n",
              "      <td>[A mass spectrometry approach for the identifi...</td>\n",
              "      <td>[NEITHER, BACKGROUND, BACKGROUND, METHOD, METH...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              document  ...                                             labels\n",
              "755     doi: 10.1172/jci.insight.96029  ...  [NEITHER, BACKGROUND, BACKGROUND, OBJECTIVE, B...\n",
              "697        doi: 10.1126/sciadv.1701676  ...  [NEITHER, BACKGROUND, BACKGROUND, BACKGROUND, ...\n",
              "918          doi: 10.3390/atmos9070240  ...  [NEITHER, BACKGROUND, OBJECTIVE, METHOD, RESUL...\n",
              "842  doi: 10.1371/journal.pone.0154077  ...  [NEITHER, BACKGROUND, METHOD, METHOD, RESULT, ...\n",
              "125     doi: 10.1016/j.abb.2018.03.026  ...  [NEITHER, BACKGROUND, BACKGROUND, METHOD, METH...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qlBFaRCHTue",
        "outputId": "8edcff19-8c31-44d3-8acb-87ac28e03513"
      },
      "source": [
        "data_structure.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   document   1014 non-null   object\n",
            " 1   sentences  1014 non-null   object\n",
            " 2   labels     1014 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 23.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "Dl_A1POCHT2x",
        "outputId": "875868c7-7d2f-4aaa-b7c5-2053891a1a09"
      },
      "source": [
        "data_structure.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1014</td>\n",
              "      <td>1014</td>\n",
              "      <td>1014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1014</td>\n",
              "      <td>1012</td>\n",
              "      <td>753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>doi: 10.1016/j.jhydrol.2018.11.026</td>\n",
              "      <td>[Synthesis of Dibenzo[hi,st\\n]ovalene and Its ...</td>\n",
              "      <td>[NEITHER, BACKGROUND]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  document  ...                 labels\n",
              "count                                 1014  ...                   1014\n",
              "unique                                1014  ...                    753\n",
              "top     doi: 10.1016/j.jhydrol.2018.11.026  ...  [NEITHER, BACKGROUND]\n",
              "freq                                     1  ...                     10\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUFF5vV-Hswf"
      },
      "source": [
        "### Split to sentences and labels and regroup the document\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "iTzC76llHUE7",
        "outputId": "5340dd21-3351-4053-8592-a7ccefe74c23"
      },
      "source": [
        "sentences_structure = data_structure['sentences'].explode().reset_index().rename(\n",
        "    columns={'index': 'doc_id', 'sentences': 'sentence'})\n",
        "sentences_structure\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Concordance Between Different Amyloid Immunoas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Importance Visual assessment of amyloid positr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Several immunoassays have been developed to me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>The agreement between CSF Aβ42 measures from d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Objective To determine the concordance between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10543</th>\n",
              "      <td>1013</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10544</th>\n",
              "      <td>1013</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10545</th>\n",
              "      <td>1013</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10546</th>\n",
              "      <td>1013</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>1013</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10548 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence\n",
              "0           0  Concordance Between Different Amyloid Immunoas...\n",
              "1           0  Importance Visual assessment of amyloid positr...\n",
              "2           0  Several immunoassays have been developed to me...\n",
              "3           0  The agreement between CSF Aβ42 measures from d...\n",
              "4           0  Objective To determine the concordance between...\n",
              "...       ...                                                ...\n",
              "10543    1013  Instead, SBPs sample a range of conformations ...\n",
              "10544    1013  Certain non-transported ligands leave the stru...\n",
              "10545    1013  Intriguingly, in some cases, similar SBP confo...\n",
              "10546    1013  In this case, the inability for transport aris...\n",
              "10547    1013  Our results reveal the complex interplay betwe...\n",
              "\n",
              "[10548 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ixe6-rUpIJdS",
        "outputId": "1135c5f6-0bb7-4b36-a7c3-fdf32ffa8d6f"
      },
      "source": [
        "labels_structure = data_structure['labels'].explode().reset_index().rename(\n",
        "    columns={'index': 'doc_id', 'labels': 'label'})\n",
        "labels_structure"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NEITHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10543</th>\n",
              "      <td>1013</td>\n",
              "      <td>METHOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10544</th>\n",
              "      <td>1013</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10545</th>\n",
              "      <td>1013</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10546</th>\n",
              "      <td>1013</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>1013</td>\n",
              "      <td>CONCLUSION</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10548 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id       label\n",
              "0           0     NEITHER\n",
              "1           0  BACKGROUND\n",
              "2           0  BACKGROUND\n",
              "3           0  BACKGROUND\n",
              "4           0   OBJECTIVE\n",
              "...       ...         ...\n",
              "10543    1013      METHOD\n",
              "10544    1013      RESULT\n",
              "10545    1013      RESULT\n",
              "10546    1013      RESULT\n",
              "10547    1013  CONCLUSION\n",
              "\n",
              "[10548 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "fnMcyCyxIY7Y",
        "outputId": "4d6930a3-a57a-4404-87ea-acd01c17b89a"
      },
      "source": [
        "structure = pd.merge(sentences_structure,labels_structure, left_index=True, right_index=True).rename( \n",
        "    columns = {\"doc_id_x\" : \"doc_id\"}).drop( columns= \"doc_id_y\")\n",
        "structure"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Concordance Between Different Amyloid Immunoas...</td>\n",
              "      <td>NEITHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Importance Visual assessment of amyloid positr...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Several immunoassays have been developed to me...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>The agreement between CSF Aβ42 measures from d...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Objective To determine the concordance between...</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10543</th>\n",
              "      <td>1013</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "      <td>METHOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10544</th>\n",
              "      <td>1013</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10545</th>\n",
              "      <td>1013</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10546</th>\n",
              "      <td>1013</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>1013</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "      <td>CONCLUSION</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10548 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence       label\n",
              "0           0  Concordance Between Different Amyloid Immunoas...     NEITHER\n",
              "1           0  Importance Visual assessment of amyloid positr...  BACKGROUND\n",
              "2           0  Several immunoassays have been developed to me...  BACKGROUND\n",
              "3           0  The agreement between CSF Aβ42 measures from d...  BACKGROUND\n",
              "4           0  Objective To determine the concordance between...   OBJECTIVE\n",
              "...       ...                                                ...         ...\n",
              "10543    1013  Instead, SBPs sample a range of conformations ...      METHOD\n",
              "10544    1013  Certain non-transported ligands leave the stru...      RESULT\n",
              "10545    1013  Intriguingly, in some cases, similar SBP confo...      RESULT\n",
              "10546    1013  In this case, the inability for transport aris...      RESULT\n",
              "10547    1013  Our results reveal the complex interplay betwe...  CONCLUSION\n",
              "\n",
              "[10548 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCYwfDz5KIpw"
      },
      "source": [
        "# Baseline Model for Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PUnCXq2hPdi",
        "outputId": "e001ea1d-41a6-4260-fc88-f75cc8637eab"
      },
      "source": [
        "from random import seed\n",
        "from random import sample\n",
        "\n",
        "# select 90 % of doc_id at random from all the structure dataset for training the baseline model\n",
        "\n",
        "# seed random number generator\n",
        "seed(10)\n",
        "\n",
        "# select a subset without replacement\n",
        "subset = sample(set(structure[\"doc_id\"].unique()) , int(len(data_structure)*0.9)) # 1014 * 0,9 = 912 abstracts were used\n",
        "\n",
        "print(subset)\n",
        "len(set(subset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[585, 33, 439, 494, 591, 15, 211, 473, 832, 503, 843, 284, 669, 830, 164, 35, 533, 501, 335, 77, 255, 975, 992, 763, 369, 45, 430, 880, 142, 617, 363, 390, 431, 290, 846, 691, 268, 467, 178, 702, 310, 677, 371, 136, 976, 786, 986, 245, 450, 628, 384, 988, 596, 4, 241, 137, 199, 931, 973, 549, 374, 790, 919, 966, 321, 682, 562, 461, 446, 481, 66, 668, 598, 332, 864, 513, 160, 862, 229, 422, 244, 37, 32, 508, 308, 837, 621, 673, 73, 546, 875, 82, 153, 393, 580, 383, 615, 921, 115, 794, 791, 98, 452, 170, 826, 195, 357, 443, 424, 456, 251, 697, 281, 146, 632, 534, 182, 885, 122, 273, 466, 309, 168, 676, 664, 840, 991, 796, 180, 491, 913, 355, 995, 445, 935, 5, 557, 729, 44, 339, 327, 248, 81, 977, 458, 414, 961, 162, 399, 507, 689, 247, 753, 537, 278, 532, 1010, 616, 511, 64, 910, 996, 690, 472, 410, 139, 987, 554, 941, 907, 551, 397, 852, 718, 169, 572, 451, 101, 425, 36, 2, 449, 548, 943, 51, 358, 94, 155, 111, 622, 464, 818, 496, 985, 469, 945, 793, 938, 457, 351, 743, 265, 807, 714, 819, 433, 336, 665, 858, 535, 157, 757, 243, 330, 633, 1012, 703, 200, 658, 602, 589, 643, 490, 25, 119, 303, 967, 252, 735, 296, 91, 47, 611, 563, 108, 292, 166, 686, 488, 144, 989, 609, 849, 196, 828, 186, 871, 605, 957, 436, 212, 912, 700, 315, 474, 711, 898, 739, 808, 869, 680, 568, 213, 272, 781, 373, 118, 642, 746, 7, 214, 434, 624, 418, 391, 667, 204, 71, 755, 783, 56, 356, 260, 368, 969, 742, 198, 792, 289, 477, 758, 301, 518, 855, 519, 269, 868, 911, 654, 349, 844, 283, 857, 815, 775, 601, 884, 85, 552, 375, 717, 172, 984, 835, 577, 67, 772, 313, 16, 766, 881, 738, 329, 75, 406, 741, 382, 725, 620, 190, 246, 974, 760, 97, 569, 54, 225, 583, 851, 981, 770, 890, 1013, 1005, 607, 695, 401, 206, 347, 588, 908, 804, 699, 334, 48, 592, 829, 932, 578, 953, 863, 940, 917, 175, 161, 120, 685, 353, 891, 31, 954, 523, 713, 90, 653, 670, 1009, 732, 61, 149, 455, 482, 688, 462, 716, 618, 179, 362, 785, 814, 838, 525, 809, 842, 765, 99, 906, 156, 42, 191, 194, 672, 1011, 730, 623, 385, 657, 53, 839, 318, 228, 50, 593, 896, 102, 655, 773, 684, 892, 43, 405, 749, 79, 646, 619, 1004, 777, 948, 415, 479, 811, 38, 177, 600, 847, 856, 824, 692, 96, 639, 121, 240, 109, 432, 604, 784, 924, 836, 590, 802, 486, 250, 545, 297, 12, 649, 395, 234, 964, 522, 485, 599, 408, 223, 294, 983, 736, 193, 543, 26, 76, 409, 956, 17, 440, 346, 897, 659, 367, 652, 487, 650, 19, 210, 130, 752, 666, 968, 526, 877, 428, 644, 128, 878, 126, 28, 733, 860, 127, 394, 69, 14, 444, 378, 338, 93, 319, 215, 946, 24, 282, 86, 27, 359, 192, 528, 235, 233, 171, 95, 540, 737, 949, 497, 947, 997, 831, 365, 768, 340, 834, 547, 135, 129, 640, 46, 883, 6, 78, 820, 40, 465, 870, 803, 72, 392, 606, 274, 635, 147, 361, 316, 413, 495, 797, 1, 726, 132, 325, 608, 264, 218, 448, 731, 74, 780, 30, 324, 721, 311, 447, 800, 779, 893, 744, 571, 675, 845, 565, 674, 813, 994, 13, 614, 453, 342, 709, 59, 933, 916, 237, 423, 89, 320, 927, 512, 527, 720, 475, 231, 612, 769, 524, 734, 173, 259, 745, 902, 637, 22, 489, 302, 817, 706, 574, 500, 140, 441, 253, 266, 951, 660, 288, 1002, 613, 561, 328, 866, 510, 386, 1000, 787, 556, 841, 344, 460, 270, 267, 504, 389, 312, 41, 641, 597, 18, 65, 493, 520, 187, 222, 113, 337, 761, 776, 509, 478, 52, 34, 928, 821, 219, 159, 584, 854, 322, 492, 859, 276, 762, 123, 708, 663, 825, 263, 306, 403, 197, 861, 636, 539, 343, 955, 402, 275, 918, 483, 202, 354, 962, 107, 476, 232, 771, 87, 882, 926, 106, 719, 853, 905, 722, 904, 333, 701, 872, 751, 516, 174, 833, 587, 150, 256, 696, 704, 208, 145, 724, 420, 426, 625, 435, 782, 850, 236, 922, 656, 567, 750, 372, 3, 514, 901, 133, 936, 594, 506, 295, 299, 463, 427, 201, 11, 227, 381, 661, 710, 152, 416, 230, 400, 116, 959, 993, 239, 417, 154, 879, 286, 188, 558, 920, 538, 747, 570, 778, 60, 57, 723, 258, 285, 944, 576, 929, 323, 138, 774, 348, 262, 293, 8, 740, 651, 822, 715, 671, 810, 679, 914, 795, 279, 789, 80, 10, 480, 62, 9, 960, 387, 542, 125, 484, 626, 631, 366, 459, 254, 874, 707, 978, 217, 39, 610, 221, 216, 167, 805, 681, 291, 29, 131, 307, 573, 437, 421, 767, 141, 438, 887, 84, 376, 579, 939, 326, 380, 379, 990, 92, 124, 341, 648, 1003, 662, 1006, 148, 536, 647, 360, 925, 226, 754, 634, 287, 894, 224, 442, 627, 581, 100, 564, 555, 63, 1001, 823, 531, 471, 728, 645, 873, 163, 21, 404, 560, 923, 937, 915, 103, 694, 396, 58, 727, 105, 958, 277, 470, 158, 798, 165, 705, 304, 185, 970, 827, 865, 930, 498, 205, 867, 566, 23, 300, 888, 529, 515, 189, 550, 816, 0, 398, 350, 407, 980, 88]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "912"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gpcs5H-JjFW",
        "outputId": "2ea0b3c3-e15c-4346-b63e-e645298b6a85"
      },
      "source": [
        "# doc_id for the training dataset\n",
        "\n",
        "coplimentary_subset = set(structure[\"doc_id\"].unique()) - set(subset)\n",
        "print(coplimentary_subset)\n",
        "len(coplimentary_subset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{517, 521, 530, 20, 541, 544, 553, 559, 49, 55, 575, 68, 70, 582, 586, 83, 595, 603, 104, 110, 112, 114, 117, 629, 630, 638, 134, 143, 151, 678, 683, 687, 176, 181, 693, 183, 184, 698, 712, 203, 207, 209, 220, 748, 238, 242, 756, 759, 249, 764, 257, 261, 271, 788, 280, 799, 801, 806, 298, 812, 305, 314, 317, 331, 848, 345, 352, 364, 876, 370, 886, 377, 889, 895, 899, 388, 900, 903, 909, 411, 412, 419, 934, 429, 942, 950, 952, 963, 965, 454, 971, 972, 979, 468, 982, 998, 999, 1007, 1008, 499, 502, 505}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb5yO8NJ66hJ"
      },
      "source": [
        "# initialize empty dictionary with keys the number of sentences occured in an abstract\n",
        "\n",
        "dict_distribution = {}\n",
        "max_sentences = []\n",
        "\n",
        "for index_str in subset:\n",
        "  max_sentences.append(len(structure[structure [\"doc_id\"] == index_str]))\n",
        "\n",
        "for row in set(max_sentences):\n",
        "    dict_distribution[row] = {} \n",
        "    for idx in range(row):\n",
        "        dict_distribution[row][idx+1] = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVx1u9vu92hz"
      },
      "source": [
        "# populate dictionary\n",
        "\n",
        "for index_str in subset:\n",
        "  abstr = structure[structure [\"doc_id\"] == index_str]\n",
        "  length_sentence_str = len(abstr)\n",
        "  i = 1\n",
        "  for index_str_basel, k in abstr.iterrows():\n",
        "    a = structure.loc[index_str_basel][\"label\"]\n",
        "    b = dict_distribution[length_sentence_str][i]\n",
        "    b.append(a)\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbnzgcuWyht3",
        "outputId": "b6f9d632-5e85-4a7d-e840-2d14a6c2508d"
      },
      "source": [
        "# Example\n",
        "\n",
        "dict_distribution [20] # in our training dataset the abstracts with 20 sentences present the following labels for each sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: ['NEITHER', 'NEITHER', 'NEITHER'],\n",
              " 2: ['OBJECTIVE', 'OBJECTIVE', 'BACKGROUND'],\n",
              " 3: ['OBJECTIVE', 'BACKGROUND', 'BACKGROUND'],\n",
              " 4: ['OBJECTIVE', 'OBJECTIVE', 'BACKGROUND'],\n",
              " 5: ['OBJECTIVE', 'OBJECTIVE', 'BACKGROUND'],\n",
              " 6: ['OBJECTIVE', 'METHOD', 'BACKGROUND'],\n",
              " 7: ['OBJECTIVE', 'METHOD', 'OBJECTIVE'],\n",
              " 8: ['OBJECTIVE', 'OBJECTIVE', 'METHOD'],\n",
              " 9: ['OBJECTIVE', 'RESULT', 'METHOD'],\n",
              " 10: ['OBJECTIVE', 'RESULT', 'METHOD'],\n",
              " 11: ['METHOD', 'RESULT', 'METHOD'],\n",
              " 12: ['OBJECTIVE', 'RESULT', 'METHOD'],\n",
              " 13: ['OBJECTIVE', 'RESULT', 'METHOD'],\n",
              " 14: ['OBJECTIVE', 'RESULT', 'RESULT'],\n",
              " 15: ['OBJECTIVE', 'RESULT', 'RESULT'],\n",
              " 16: ['OBJECTIVE', 'RESULT', 'RESULT'],\n",
              " 17: ['CONCLUSION', 'OBJECTIVE', 'RESULT'],\n",
              " 18: ['OBJECTIVE', 'CONCLUSION', 'CONCLUSION'],\n",
              " 19: ['OBJECTIVE', 'CONCLUSION', 'CONCLUSION'],\n",
              " 20: ['OBJECTIVE', 'CONCLUSION', 'OBJECTIVE']}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWh1BOcBJTpu",
        "outputId": "511edd10-9947-4800-d084-ac6fa36b288d"
      },
      "source": [
        "# creating a list of the actual labels from the testing dataset\n",
        "\n",
        "y_actual_structure_baseline = []\n",
        "\n",
        "for index_str_tr in coplimentary_subset:\n",
        "  abstr_train = structure[structure [\"doc_id\"] == index_str_tr]\n",
        "\n",
        "  for lab_str_bas in abstr_train[\"label\"]:\n",
        "    y_actual_structure_baseline.append(lab_str_bas)\n",
        "\n",
        "print(f'{len(y_actual_structure_baseline)} sentences where used for prediction from the 102 abstracts')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1017 sentences where used for prediction from the 102 abstracts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4XxkLS2PyWT",
        "outputId": "782c2244-7f41-428a-9d0e-afa72c2e1dd1"
      },
      "source": [
        "# creating a list of the predicted labels from the testing dataset according to the most common from the dictionary previously created\n",
        "\n",
        "y_predictions_structure_baseline = []\n",
        "\n",
        "for index_str_tr in coplimentary_subset:\n",
        "  abstr_train = structure[structure [\"doc_id\"] == index_str_tr]\n",
        "  number_of_sentences = len(abstr_train)\n",
        "  for n in range(number_of_sentences):\n",
        "    \n",
        "    try:\n",
        "      spot = dict_distribution[number_of_sentences][n+1]\n",
        "    except KeyError:\n",
        "      spot = dict_distribution[119][119] \n",
        "      # if error is raised because the dictionary does not contain this number of sentences\n",
        "      # get the abstract with the most sentences which exists in this seed (10) for the subsets\n",
        "\n",
        "    prediction_bas = Counter(spot).most_common(1)[0][0]\n",
        "    y_predictions_structure_baseline.append(prediction_bas)\n",
        "\n",
        "print(f'{len(y_predictions_structure_baseline)} sentences where used for prediction from the 102 abstracts') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1017 sentences where used for prediction from the 102 abstracts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzTF-bCcgZtf"
      },
      "source": [
        "### Confusion Matrix & Classification report for selected baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "r_oTRWDUh1Nv",
        "outputId": "3424766d-f8bb-430c-fcbe-e7aa3d2fec34"
      },
      "source": [
        "conf_matrix_structure_baseline = confusion_matrix ( y_true = y_actual_structure_baseline, y_pred = y_predictions_structure_baseline, \n",
        "                                                   labels = [\"NEITHER\",\"BACKGROUND\",\"OBJECTIVE\",\"METHOD\",\"RESULT\",\"CONCLUSION\"])\n",
        "pd.DataFrame( conf_matrix_structure_baseline, columns =[\"NEITHER\",\"BACKGROUND\",\"OBJECTIVE\",\"METHOD\",\"RESULT\",\"CONCLUSION\"],\n",
        "             index = [\"NEITHER\",\"BACKGROUND\",\"OBJECTIVE\",\"METHOD\",\"RESULT\",\"CONCLUSION\"] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEITHER</th>\n",
              "      <th>BACKGROUND</th>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <th>METHOD</th>\n",
              "      <th>RESULT</th>\n",
              "      <th>CONCLUSION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NEITHER</th>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BACKGROUND</th>\n",
              "      <td>0</td>\n",
              "      <td>173</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>19</td>\n",
              "      <td>35</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>METHOD</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULT</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>177</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCLUSION</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            NEITHER  BACKGROUND  OBJECTIVE  METHOD  RESULT  CONCLUSION\n",
              "NEITHER         101           0          1       0       0           0\n",
              "BACKGROUND        0         173          1      25      26           2\n",
              "OBJECTIVE         0          64         51      19      35          20\n",
              "METHOD            0          29          1      52      56           5\n",
              "RESULT            0           8          0      29     177          23\n",
              "CONCLUSION        0           2          1       0      23          93"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5hRM1EsgbDD",
        "outputId": "4460dcf3-d0ef-4923-b74a-300acf8e007e"
      },
      "source": [
        "print( classification_report( y_true = y_actual_structure_baseline , y_pred = y_predictions_structure_baseline) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.63      0.76      0.69       227\n",
            "  CONCLUSION       0.65      0.78      0.71       119\n",
            "      METHOD       0.42      0.36      0.39       143\n",
            "     NEITHER       1.00      0.99      1.00       102\n",
            "   OBJECTIVE       0.93      0.27      0.42       189\n",
            "      RESULT       0.56      0.75      0.64       237\n",
            "\n",
            "    accuracy                           0.64      1017\n",
            "   macro avg       0.70      0.65      0.64      1017\n",
            "weighted avg       0.68      0.64      0.62      1017\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZRvMz39PRGp"
      },
      "source": [
        "# Text Classification with fastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXO2cwxxu3f_"
      },
      "source": [
        "### Argument Dataset Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "v5bgZZQ9u16w",
        "outputId": "c5dac530-1deb-4117-8a23-3c8de0404c28"
      },
      "source": [
        "arguments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gender Differences in Anxiety and Depression b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Abstract</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Background/aims: The aim of this prospective s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Methods: AUD severity, state and trait anxiety...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Follow-up assessments were performed at 6 and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31999</th>\n",
              "      <td>2685</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32000</th>\n",
              "      <td>2685</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32001</th>\n",
              "      <td>2685</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32002</th>\n",
              "      <td>2685</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32003</th>\n",
              "      <td>2685</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32004 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence label\n",
              "0           0  Gender Differences in Anxiety and Depression b...     0\n",
              "1           0                                           Abstract     0\n",
              "2           0  Background/aims: The aim of this prospective s...     0\n",
              "3           0  Methods: AUD severity, state and trait anxiety...     0\n",
              "4           0  Follow-up assessments were performed at 6 and ...     0\n",
              "...       ...                                                ...   ...\n",
              "31999    2685  Instead, SBPs sample a range of conformations ...     0\n",
              "32000    2685  Certain non-transported ligands leave the stru...     0\n",
              "32001    2685  Intriguingly, in some cases, similar SBP confo...     0\n",
              "32002    2685  In this case, the inability for transport aris...     0\n",
              "32003    2685  Our results reveal the complex interplay betwe...     2\n",
              "\n",
              "[32004 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIiJWf3lXJbN"
      },
      "source": [
        "### Use the split datasets to create txt files that have the correct format for the fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDLff3D9WN6v"
      },
      "source": [
        "# merge x & y datasets\n",
        "\n",
        "train_arg = pd.merge(y_train_arg,X_train_arg, left_index=True, right_index=True)\n",
        "val_arg = pd.merge(y_val_arg,X_val_arg, left_index=True, right_index=True)\n",
        "test_arg = pd.merge(y_test_arg,X_test_arg, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGhvhas-WODj",
        "outputId": "a550d329-a0ea-43ed-9c1b-c6662bd06677"
      },
      "source": [
        "# saving index of each dataset\n",
        "train_arg_index = train_arg.index\n",
        "val_arg_index = val_arg.index\n",
        "test_arg_index = test_arg.index\n",
        "\n",
        "print(\"test: \", len(test_arg_index),\"sentences\",\n",
        "      \"\\nvalidation: \", len(val_arg_index),\"sentences\",\n",
        "      \"\\ntrain: \", len(train_arg_index),\"sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test:  3201 sentences \n",
            "validation:  3169 sentences \n",
            "train:  25634 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlqCdvooWOM9"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for training\n",
        "\n",
        "with open('train_arg.txt', 'w') as train:\n",
        "  for index in train_arg_index:\n",
        "    sen = train_arg.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = train_arg.loc[index][\"label\"]\n",
        "    train.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "train.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-3ux1VcWOU1"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for validation\n",
        "\n",
        "with open('valid_arg.txt', 'w') as valid:\n",
        "  for index in val_arg_index:\n",
        "    sen = val_arg.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = val_arg.loc[index][\"label\"]\n",
        "    valid.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "valid.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvybyI-cWU6n"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for testing\n",
        "\n",
        "with open('test_arg.txt', 'w') as tes:\n",
        "  for index in test_arg_index:\n",
        "    sen = test_arg.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = test_arg.loc[index][\"label\"]\n",
        "    tes.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "tes.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBp6ai-gu_Az"
      },
      "source": [
        "### Structure Dataset Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "TdtHwlL3vFjs",
        "outputId": "c1b6832f-ee37-41bb-f7d8-4b4b6d075016"
      },
      "source": [
        "structure"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Concordance Between Different Amyloid Immunoas...</td>\n",
              "      <td>NEITHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Importance Visual assessment of amyloid positr...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Several immunoassays have been developed to me...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>The agreement between CSF Aβ42 measures from d...</td>\n",
              "      <td>BACKGROUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Objective To determine the concordance between...</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10543</th>\n",
              "      <td>1013</td>\n",
              "      <td>Instead, SBPs sample a range of conformations ...</td>\n",
              "      <td>METHOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10544</th>\n",
              "      <td>1013</td>\n",
              "      <td>Certain non-transported ligands leave the stru...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10545</th>\n",
              "      <td>1013</td>\n",
              "      <td>Intriguingly, in some cases, similar SBP confo...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10546</th>\n",
              "      <td>1013</td>\n",
              "      <td>In this case, the inability for transport aris...</td>\n",
              "      <td>RESULT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>1013</td>\n",
              "      <td>Our results reveal the complex interplay betwe...</td>\n",
              "      <td>CONCLUSION</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10548 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       doc_id                                           sentence       label\n",
              "0           0  Concordance Between Different Amyloid Immunoas...     NEITHER\n",
              "1           0  Importance Visual assessment of amyloid positr...  BACKGROUND\n",
              "2           0  Several immunoassays have been developed to me...  BACKGROUND\n",
              "3           0  The agreement between CSF Aβ42 measures from d...  BACKGROUND\n",
              "4           0  Objective To determine the concordance between...   OBJECTIVE\n",
              "...       ...                                                ...         ...\n",
              "10543    1013  Instead, SBPs sample a range of conformations ...      METHOD\n",
              "10544    1013  Certain non-transported ligands leave the stru...      RESULT\n",
              "10545    1013  Intriguingly, in some cases, similar SBP confo...      RESULT\n",
              "10546    1013  In this case, the inability for transport aris...      RESULT\n",
              "10547    1013  Our results reveal the complex interplay betwe...  CONCLUSION\n",
              "\n",
              "[10548 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPK-mAsAYKTa"
      },
      "source": [
        "### Splitting Dataset Procedure\n",
        "\n",
        "---\n",
        "* Training dataset\n",
        "* Validation dataset\n",
        "* Test dataset (unseen dataset)\n",
        "---\n",
        "At first, we will split the Original dataset into two parts:\n",
        "\n",
        "* Train-Validation dataset\n",
        "* Test dataset \n",
        "\n",
        "Secondly, we will split the Train-Validation dataset into another two parts:\n",
        "* Train dataset\n",
        "* Validation dataset\n",
        "\n",
        "#### Note: Stratified sampling was used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUTuBbKaZEJu",
        "outputId": "45fe1e47-8a34-4854-c3f4-1ccd705dca64"
      },
      "source": [
        "# The raw input (sentences)\n",
        "X_structure = structure['sentence']\n",
        "\n",
        "X_structure.head(17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Concordance Between Different Amyloid Immunoas...\n",
              "1     Importance Visual assessment of amyloid positr...\n",
              "2     Several immunoassays have been developed to me...\n",
              "3     The agreement between CSF Aβ42 measures from d...\n",
              "4     Objective To determine the concordance between...\n",
              "5     Design, Setting, and Participants The study in...\n",
              "6     Levels of CSF Aβ42 were analyzed using the cla...\n",
              "7     Concentrations of CSF Aβ were assessed using a...\n",
              "8     Main Outcomes and Measures The concordance of ...\n",
              "9     Results Of 262 participants (mean [SD] age, 70...\n",
              "10    The mass spectrometry–derived Aβ42 values show...\n",
              "11    The signal in the classic Aβ42-INNOTEST assay ...\n",
              "12    However, the classic Aβ42-INNOTEST assay showe...\n",
              "13    The accuracies of the newer assays improved si...\n",
              "14    A combination of the Aβ42:Aβ40 ratio and T-tau...\n",
              "15    Conclusions and Relevance Concentrations of CS...\n",
              "16    These findings suggest the benefit of implemen...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scjkPEdkZEcW",
        "outputId": "082fa139-f01d-4aa8-b8e1-f6248a7f970b"
      },
      "source": [
        "# The raw output (Labels : \"NEITHER\",\"BACKGROUND\",\"OBJECTIVE\",\"METHOD\",\"RESULT\",\"CONCLUSION\" )\n",
        "y_structure = structure['label']\n",
        "\n",
        "y_structure.head(17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        NEITHER\n",
              "1     BACKGROUND\n",
              "2     BACKGROUND\n",
              "3     BACKGROUND\n",
              "4      OBJECTIVE\n",
              "5         METHOD\n",
              "6         METHOD\n",
              "7         METHOD\n",
              "8         RESULT\n",
              "9         RESULT\n",
              "10        RESULT\n",
              "11        RESULT\n",
              "12        RESULT\n",
              "13        RESULT\n",
              "14        RESULT\n",
              "15    CONCLUSION\n",
              "16    CONCLUSION\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L27k43PwzPi"
      },
      "source": [
        "X_train_val_str, X_test_str, y_train_val_str, y_test_str = train_test_split(X_structure,\n",
        "                                                            y_structure,\n",
        "                                                            test_size=0.05,\n",
        "                                                            random_state=10,\n",
        "                                                            stratify = y_structure)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwOYJ4DKw0Bg"
      },
      "source": [
        "X_train_str, X_val_str, y_train_str, y_val_str = train_test_split(X_train_val_str,\n",
        "                                                  y_train_val_str,\n",
        "                                                  test_size=0.05, \n",
        "                                                  random_state=50,\n",
        "                                                  stratify = y_train_val_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_wFeYvGw5G5",
        "outputId": "f2488b6b-4ca8-476a-93a9-99ba4c1fdd75"
      },
      "source": [
        "print(f'X_train_val_str shape: {X_train_val_str.shape}')\n",
        "print(f'y_train_val_str shape: {y_train_val_str.shape}')\n",
        "print()\n",
        "\n",
        "print(f'X_train_str shape: {X_train_str.shape}')\n",
        "print(f'y_train_str shape: {y_train_str.shape}')\n",
        "print()\n",
        "\n",
        "print(f'X_val_str shape: {X_val_str.shape}')\n",
        "print(f'y_val_str shape: {y_val_str.shape}')\n",
        "\n",
        "print()\n",
        "print(f'X_test_str shape: {X_test_str.shape}')\n",
        "print(f'y_test_str shape: {y_test_str.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_val_str shape: (10020,)\n",
            "y_train_val_str shape: (10020,)\n",
            "\n",
            "X_train_str shape: (9519,)\n",
            "y_train_str shape: (9519,)\n",
            "\n",
            "X_val_str shape: (501,)\n",
            "y_val_str shape: (501,)\n",
            "\n",
            "X_test_str shape: (528,)\n",
            "y_test_str shape: (528,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeEVJGFEawjd"
      },
      "source": [
        "### Use the split datasets to create txt files that have the correct format for the fasttext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8_GYPZ1axKc"
      },
      "source": [
        "# merge x & y datasets\n",
        "\n",
        "train_str = pd.merge(y_train_str,X_train_str, left_index=True, right_index=True)\n",
        "val_str = pd.merge(y_val_str,X_val_str, left_index=True, right_index=True)\n",
        "test_str = pd.merge(y_test_str,X_test_str, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVWgE0p5axWG",
        "outputId": "59873f4e-656b-4b80-efc3-8daf2f8d13dd"
      },
      "source": [
        "# saving index of each dataset\n",
        "train_str_index = train_str.index\n",
        "val_str_index = val_str.index\n",
        "test_str_index = test_str.index\n",
        "\n",
        "print(\"test: \", len(test_str_index),\"sentences\",\n",
        "      \"\\nvalidation: \", len(val_str_index),\"sentences\",\n",
        "      \"\\ntrain: \", len(train_str_index),\"sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test:  528 sentences \n",
            "validation:  501 sentences \n",
            "train:  9519 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyynFVKSaxZW"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for training\n",
        "\n",
        "with open('train_str.txt', 'w') as train2:\n",
        "  for index in train_str_index:\n",
        "    sen = train_str.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = train_str.loc[index][\"label\"]\n",
        "    train2.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "train2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVXR_WHaaxcl"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for validation\n",
        "\n",
        "with open('valid_str.txt', 'w') as valid2:\n",
        "  for index in val_str_index:\n",
        "    sen = val_str.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = val_str.loc[index][\"label\"]\n",
        "    valid2.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "valid2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4uErkAjaxgg"
      },
      "source": [
        "# create txt file with the correct format that the fasttext model expects to read for testing\n",
        "\n",
        "with open('test_str.txt', 'w') as tes2:\n",
        "  for index in test_str_index:\n",
        "    sen = test_str.loc[index][\"sentence\"].replace('\\n','')\n",
        "    label = test_str.loc[index][\"label\"]\n",
        "    tes2.write(f'__label__{label} {sen}\\n')\n",
        "\n",
        "tes2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6savdH_jcO82"
      },
      "source": [
        "# Fasttext implementation for the arguments dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivBmG8PQcnzv"
      },
      "source": [
        "The actual model fastText implements is rather simple as we can see in the image below -- the negative log-likelihood the model tries to minimize in training is \n",
        "\n",
        "$$ - \\frac{1}{N} \\sum_{n=1}^{N} y_n \\log(f(BAd_n)) $$\n",
        "\n",
        "where \n",
        "- $d_n$ is the representation of the $n$-th document (denoted `hidden` in the image below)\n",
        "- $A$ is the \"document\" embedding matrix \n",
        "- $B$ is the linear projection from \"document\" embeddings to output classes\n",
        "- $f$ is the `softmax` non-linearity function\n",
        "- $y_n$ is the label of the $n$-th document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kyf3-XaeHg6",
        "outputId": "ea5112ac-b538-4391-907f-4f599c0608d9"
      },
      "source": [
        "# Install fasttext \n",
        "\n",
        "!pip install fasttext\n",
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.7.1-py2.py3-none-any.whl (200 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3091430 sha256=9df7401376504a3853b0d2cc3eba7aec6c2a594e56a651640cef9c1013371e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgen2elgwkwh"
      },
      "source": [
        "### Basic implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbZa2UJEeavt"
      },
      "source": [
        "# Automatic hyperparameter optimization, default time is 5 minutes\n",
        "model_basic_arg = fasttext.train_supervised( input = 'train_arg.txt',autotuneValidationFile = \"valid_arg.txt\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D90CEBKOnas1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4799e315-8a34-437a-e99a-839dd2696c78"
      },
      "source": [
        "# Save model\n",
        "\n",
        "model_basic_arg.save_model(\"model_basic_arg.bin\")\n",
        "\n",
        "# Load model \n",
        "# model_basic_arg = fasttext.load_model(\"model_basic_arg.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKEbRgddo3uc",
        "outputId": "cf61171b-f719-4d05-8040-1e94de541b24"
      },
      "source": [
        "# Dictionary of all words\n",
        "print(\"Size = \",len(model_basic_arg.words))\n",
        "# Labels\n",
        "model_basic_arg.labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size =  60597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__0', '__label__1', '__label__2']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWvUn1EyrhKd",
        "outputId": "7d6d363d-4ca5-416b-a291-4e5d1b38de38"
      },
      "source": [
        "def print_results(N, p, r):\n",
        "    print(\"Number of test observations\\t\" + str(N))\n",
        "    print(\"P@{} : Precision\\t\\t\\t{:.3f}\".format(1, p))\n",
        "    print(\"R@{} : Recall\\t\\t\\t{:.3f}\".format(1, r))\n",
        "\n",
        "print_results(*model_basic_arg.test(\"test_arg.txt\"))\n",
        "\n",
        "# Number of test observations\t3201\n",
        "# P@1 : Precision\t\t\t0.794\n",
        "# R@1 : Recall\t\t\t0.794\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test observations\t3201\n",
            "P@1 : Precision\t\t\t0.794\n",
            "R@1 : Recall\t\t\t0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIazcpt4fAX_",
        "outputId": "02ba3c0d-cd53-42af-fbf0-c1d013e1f22f"
      },
      "source": [
        "def print_parameters(model_basic_arg):\n",
        "  print(\n",
        "    \" Model Parameters:\",\"\\n\",\n",
        "    \"learning rate [0.1]\\t\\t\\t\",model_basic_arg.lr,\"\\n\",\n",
        "    \"size of word vectors [100]\\t\\t\",model_basic_arg.dim,\"\\n\",\n",
        "    \"size of the context window [5]\\t\\t\",model_basic_arg.ws,\"\\n\",\n",
        "    \"number of epochs [5]\\t\\t\\t\",model_basic_arg.epoch,\"\\n\",\n",
        "    \"minimal number of word occurences [1]\\t\",model_basic_arg.minCount,\"\\n\",\n",
        "    \"minimal number of label occurences [1]\\t\",model_basic_arg.minCountLabel,\"\\n\",\n",
        "    \"min length of char ngram [0]\\t\\t\",model_basic_arg.minn,\"\\n\",\n",
        "    \"max length of char ngram [0]\\t\\t\",model_basic_arg.maxn,\"\\n\",\n",
        "    \"number of negatives sampled [5]\\t\",model_basic_arg.neg,\"\\n\",\n",
        "    \"max length of word ngram [1]\\t\\t\",model_basic_arg.wordNgrams,\"\\n\",\n",
        "    \"number of buckets [2000000]\\t\\t\",model_basic_arg.bucket,\"\\n\",\n",
        "    \"number of threads [number of cpus]\\t\",model_basic_arg.thread,\"\\n\",\n",
        "    \"sampling threshold [0.0001]\\t\\t\",model_basic_arg.t,\"\\n\",\n",
        "    \"change the rate of updates for the learning rate [100]\\t\",model_basic_arg.lrUpdateRate,\"\\n\",\n",
        "    \"loss function {ns, hs, softmax, ova} [softmax]\\t\",model_basic_arg.loss,\"\\n\"\n",
        "    )\n",
        "  \n",
        "print_parameters(model_basic_arg)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Model Parameters: \n",
            " learning rate [0.1]\t\t\t 0.2028618832874646 \n",
            " size of word vectors [100]\t\t 169 \n",
            " size of the context window [5]\t\t 5 \n",
            " number of epochs [5]\t\t\t 37 \n",
            " minimal number of word occurences [1]\t 1 \n",
            " minimal number of label occurences [1]\t 0 \n",
            " min length of char ngram [0]\t\t 0 \n",
            " max length of char ngram [0]\t\t 0 \n",
            " number of negatives sampled [5]\t 5 \n",
            " max length of word ngram [1]\t\t 2 \n",
            " number of buckets [2000000]\t\t 4110692 \n",
            " number of threads [number of cpus]\t 1 \n",
            " sampling threshold [0.0001]\t\t 0.0001 \n",
            " change the rate of updates for the learning rate [100]\t 100 \n",
            " loss function {ns, hs, softmax, ova} [softmax]\t loss_name.softmax \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eikSn-lwv5Xa"
      },
      "source": [
        "# !./fasttext test-label ft_basic_arg.bin test_arg.txt\n",
        "\n",
        "# F1-Score : 0.867362  Precision : 0.828386  Recall : 0.910188   __label__0\n",
        "# F1-Score : 0.609756  Precision : 0.664137  Recall : 0.563607   __label__1\n",
        "# F1-Score : 0.459605  Precision : 0.595349  Recall : 0.374269   __label__2\n",
        "# N\t3201\n",
        "# P@1\t0.786\n",
        "# R@1\t0.786"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPHeAEzGtQ8S"
      },
      "source": [
        "# Fasttext implementation for the structure dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iEfX5pIwtYu"
      },
      "source": [
        "### Basic implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwYDKzt7fWRi"
      },
      "source": [
        "# Automatic hyperparameter optimization, default time is 5 minutes (, autotuneDuration=300)\n",
        "model_basic_str = fasttext.train_supervised( input = 'train_str.txt',autotuneValidationFile = \"valid_str.txt\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZziIM2pPotZC"
      },
      "source": [
        "# Save model\n",
        "\n",
        "model_basic_str.save_model(\"model_basic_str.bin\")\n",
        "\n",
        "# Load model \n",
        "# model_basic_str = fasttext.load_model(\"model_basic_str.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAxLCx0jp1kf",
        "outputId": "ac708934-567d-4d04-bf1a-677643af310a"
      },
      "source": [
        "# Dictionary of all words\n",
        "print(\"Size = \",len(model_basic_str.words))\n",
        "# Labels\n",
        "model_basic_str.labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size =  31715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__RESULT',\n",
              " '__label__BACKGROUND',\n",
              " '__label__OBJECTIVE',\n",
              " '__label__METHOD',\n",
              " '__label__CONCLUSION',\n",
              " '__label__NEITHER']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zA588uIqiRy",
        "outputId": "5c715108-74ad-4788-9264-390ab7d4f60a"
      },
      "source": [
        "print_results(*model_basic_str.test(\"test_str.txt\"))\n",
        "\n",
        "# Number of test observations\t528\n",
        "# P@1 : Precision\t\t\t0.638\n",
        "# R@1 : Recall\t\t\t0.638"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test observations\t528\n",
            "P@1 : Precision\t\t\t0.638\n",
            "R@1 : Recall\t\t\t0.638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLcEgfIfzOE0",
        "outputId": "0b1b176f-a664-4eac-d318-62501239a7fa"
      },
      "source": [
        "print_parameters(model_basic_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Model Parameters: \n",
            " learning rate [0.1]\t\t\t 0.08499425639667486 \n",
            " size of word vectors [100]\t\t 92 \n",
            " size of the context window [5]\t\t 5 \n",
            " number of epochs [5]\t\t\t 100 \n",
            " minimal number of word occurences [1]\t 1 \n",
            " minimal number of label occurences [1]\t 0 \n",
            " min length of char ngram [0]\t\t 0 \n",
            " max length of char ngram [0]\t\t 0 \n",
            " number of negatives sampled [5]\t 5 \n",
            " max length of word ngram [1]\t\t 2 \n",
            " number of buckets [2000000]\t\t 4110692 \n",
            " number of threads [number of cpus]\t 1 \n",
            " sampling threshold [0.0001]\t\t 0.0001 \n",
            " change the rate of updates for the learning rate [100]\t 100 \n",
            " loss function {ns, hs, softmax, ova} [softmax]\t loss_name.softmax \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2kYiRap5tcD"
      },
      "source": [
        "# Automatic hyperparameter optimization, default time is 5 minutes (, autotuneDuration=300)\n",
        "model_10_str = fasttext.train_supervised( input = 'train_str.txt',autotuneValidationFile = \"valid_str.txt\" , autotuneDuration = 600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH31EUqqAm6y",
        "outputId": "69f8de5e-72c2-403c-c271-cb6d8a228f57"
      },
      "source": [
        "print_results(*model_10_str.test(\"test_str.txt\"))\n",
        "\n",
        "# Number of test observations\t528\n",
        "# P@1 : Precision\t\t\t0.634\n",
        "# R@1 : Recall\t\t\t0.634"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test observations\t528\n",
            "P@1 : Precision\t\t\t0.634\n",
            "R@1 : Recall\t\t\t0.634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv1RJZ5IB5aW"
      },
      "source": [
        "# Automatic hyperparameter optimization, default time is 5 minutes (, autotuneDuration=300)\n",
        "model_10_arg = fasttext.train_supervised( input = 'train_arg.txt',autotuneValidationFile = \"valid_arg.txt\" , autotuneDuration = 600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlNGUtXfB5jm",
        "outputId": "3fccdfd2-4eb4-4ca0-e2d4-87b38d0b7cba"
      },
      "source": [
        "print_results(*model_10_arg.test(\"test_arg.txt\"))\n",
        "\n",
        "# Number of test observations\t3201\n",
        "# P@1 : Precision\t\t\t0.794\n",
        "# R@1 : Recall\t\t\t0.794"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test observations\t3201\n",
            "P@1 : Precision\t\t\t0.794\n",
            "R@1 : Recall\t\t\t0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCuDKm79vyCD"
      },
      "source": [
        "# !./fasttext test-label ft_basic_str.bin test_str.txt\n",
        "\n",
        "# tcmalloc: large alloc 1524408320 bytes == 0x55739fb88000 @  0x7f557df67887 0x55739d8b5d3f 0x55739d8c529d 0x55739d8c57f1 0x55739d8d27ed 0x55739d889ae5 0x7f557d004bf7 0x55739d889b4a\n",
        "# F1-Score : 0.671378  Precision : 0.641892  Recall : 0.703704   __label__RESULT\n",
        "# F1-Score : 0.675105  Precision : 0.615385  Recall : 0.747664   __label__BACKGROUND\n",
        "# F1-Score : 0.639594  Precision : 0.605769  Recall : 0.677419   __label__OBJECTIVE\n",
        "# F1-Score : 0.587413  Precision : 0.666667  Recall : 0.525000   __label__METHOD\n",
        "# F1-Score : 0.448598  Precision : 0.533333  Recall : 0.387097   __label__CONCLUSION\n",
        "# F1-Score : 0.741573  Precision : 0.868421  Recall : 0.647059   __label__NEITHER\n",
        "# N\t528\n",
        "# P@1\t0.638\n",
        "# R@1\t0.638"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}